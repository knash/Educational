{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f943cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.8.1\n",
      "torchvision 0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import super\n",
    "\"\"\"\n",
    "Implementation of Block Neural Autoregressive Flow\n",
    "http://arxiv.org/abs/1904.04676\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torchvision\n",
    "print (\"torch\",torch.__version__)\n",
    "print (\"torchvision\",torchvision.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import array\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import pprint\n",
    "import scipy\n",
    "from scipy import special\n",
    "from functools import partial\n",
    "import json\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.manifold import TSNE\n",
    "import csv\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64727ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------\n",
    "# Data\n",
    "# --------------------\n",
    "matplotlib.use('tkagg')\n",
    "class sample:\n",
    "    def __init__(self, nchan ,biasmag, batch_size, topred, seed=None):\n",
    "        self.biasmag=biasmag\n",
    "        self.batch_size=batch_size\n",
    "        self.nchan=nchan\n",
    "        self.seed=seed\n",
    "        self.topred=topred\n",
    "    def sreturn(self):\n",
    "        xvals=[]\n",
    "        yvals=[]\n",
    "        ychan=[]\n",
    "        if (self.seed==None):\n",
    "                rng = np.random\n",
    "        else:\n",
    "                rng = np.random.RandomState(self.seed)\n",
    "        #print (-1,1,(self.batch_size,self.nchan))\n",
    "        randonarr=rng.uniform(-1,1,(self.batch_size,self.nchan))*self.biasmag\n",
    "        #randonarr[:,1]=1.0*randonarr[:,0]+0.0*randonarr[:,1]\n",
    "\n",
    "\n",
    "        ntimep = 100+self.topred\n",
    "        for bb in range(self.batch_size):\n",
    "\n",
    "\n",
    "                curx=[]\n",
    "                cury=[]\n",
    "                prevarrand=np.array([])\n",
    "                perm=np.arange(4)\n",
    "                np.random.shuffle(perm)\n",
    "                #print(perm)\n",
    "                ychan.append(perm)\n",
    "                for nn in range(self.nchan):\n",
    "                        sinfac=rng.uniform(0.2,1.)*1.2\n",
    "                        sinarr=np.sin(np.arange(ntimep)*sinfac)*1\n",
    "                        cosfac=rng.uniform(0.2,1.)*1.2\n",
    "                        cosarr=np.cos(np.arange(ntimep)*cosfac)*1\n",
    "                        #print(sinfac)\n",
    "                        #print(cosfac)\n",
    "                        corrnoise=False\n",
    "                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                        if corrnoise:\n",
    "                                if prevarrand.size==0:\n",
    "                                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                                else:\n",
    "                                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                                        arrand[nn*5:]=prevarrand[0:-1*nn*5]\n",
    "                                cs=np.cumsum(arrand)\n",
    "                        else:\n",
    "                                arrand = rng.uniform(-1,1,ntimep)*0.1\n",
    "                                cs=np.cumsum(arrand+randonarr[bb][nn])+sinarr+cosarr\n",
    "\n",
    "                        #print (sinarr) \n",
    "                        curx.append(cs[:-self.topred])\n",
    "                        cury.append(cs[-self.topred:])\n",
    "                        #curx.append(np.cumsum(arrand+randonarr[bb][0]))\n",
    "                        prevarrand=arrand\n",
    "                curx=np.array(curx)\n",
    "                cury=np.array(cury)\n",
    "                #print (ychan[-1])\n",
    "                #print (curx[:,0])\n",
    "\n",
    "                curx=curx[ychan[-1]]\n",
    "                #curx=np.transpose(curx,ychan[-1])\n",
    "                #print (curx[:,0])\n",
    "                #print ()\n",
    "                cury=cury[ychan[-1]]\n",
    "     \n",
    "                xvals.append((curx))\n",
    "                yvals.append((cury))\n",
    "                #print (np.array(xvals).shape)\n",
    "                #print (np.array(yvals).shape)\n",
    "                #plt.plot(curx)\n",
    "                #plt.xlabel(\"steps\")\n",
    "                #plt.ylabel(\"position\")\n",
    "                #plt.title(\"randdwalk\")\n",
    "                #plt.show()\n",
    "                #sys.exit()\n",
    "                #input(\"Press Enter to continue...\")\n",
    "        return np.array(xvals, dtype=\"float32\"),np.array(yvals, dtype=\"float32\"),np.array(ychan, dtype=\"int64\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3166a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tspred(model,data,ntime):\n",
    "        fdata=list(data)\n",
    "        for itime in range(ntime):\n",
    "            curpred=model(fdata)\n",
    "            if (itime==0):\n",
    "                preds = curpred\n",
    "            else:\n",
    "                preds = torch.cat((preds,curpred),dim=2)\n",
    "\n",
    "            fdata[0]= torch.cat((fdata[0],curpred),dim=2)[:,:,1:]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afaec837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,nchan=4,ntime=100,n_hidden=128,n_layers=2,npoint=5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_layers=n_layers\n",
    "        self.ntime=ntime+npoint\n",
    "        self.nchan=nchan\n",
    "        self.npoint=npoint \n",
    "        self.output_size=self.nchan*self.npoint\n",
    "        self.ks=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.lin = nn.Sequential(  \n",
    "        nn.Linear(464, 2*400)\n",
    "        )\n",
    "        self.out1 = nn.Linear(self.n_hidden, self.n_hidden)\n",
    "\n",
    "        self.out = nn.Linear(self.n_hidden, self.output_size)\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=nchan,hidden_size= self.n_hidden, num_layers=self.n_layers,batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size=self.n_hidden,hidden_size= self.n_hidden, num_layers=self.n_layers,batch_first=True)\n",
    "        \n",
    "        #self.lstm1 = nn.LSTM(input_size=1,hidden_size= self.n_hidden, num_layers=self.n_layers,batch_first=True)\n",
    "        #self.soft = nn.Sequential( nn.Softmax(dim=1))\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputlstm=inputs[0]\n",
    "        inputlstmshape=inputlstm.shape\n",
    "        batchs =inputlstmshape[0]\n",
    "        inputconv=inputs[1].unsqueeze(1).transpose(1, 2)\n",
    "\n",
    "\n",
    "        #h0c = torch.zeros( self.n_layers, batchs, self.n_hidden).to('cuda')  \n",
    "        #c0c = torch.zeros( self.n_layers, batchs, self.n_hidden).to('cuda')\n",
    "        #LSc,hiddenc=self.lstm1(inputconv, (h0c,c0c)) \n",
    "\n",
    "\n",
    "        inputlstm=inputlstm.transpose(1, 2)\n",
    "\n",
    "        #print(LSc.shape)\n",
    "        #print(inputlstm.shape)\n",
    "        h0 = torch.zeros( self.n_layers, batchs, self.n_hidden).to('cuda')  \n",
    "        c0 = torch.zeros( self.n_layers, batchs, self.n_hidden).to('cuda')\n",
    "        LS,hidden=self.lstm(inputlstm,(h0,c0))\n",
    "\n",
    "        #LS,hidden=self.lstm1(LS,hidden)        \n",
    "        #output = self.out(torch.cat((LS[:,-1,:],LSc[:,-1,:]),dim=1))\n",
    "        LS=LS[:,-1,:].reshape(LS.size(0), -1)\n",
    "        output = F.relu(self.out1(LS))\n",
    "\n",
    "        output = self.out(output)\n",
    "        #print (output.shape)\n",
    "\n",
    "\n",
    "        return output.reshape(output.shape[0],self.nchan,self.npoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad810610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,nchan=4,ntime=100,n_hidden=64,n_layers=1,npoint=5):\n",
    "        super(Conv, self).__init__()\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_layers=n_layers\n",
    "        self.ntime=ntime+npoint\n",
    "        self.nchan=nchan\n",
    "        self.npoint=npoint \n",
    "        self.output_size=self.nchan*self.npoint\n",
    "        self.ks=10\n",
    "\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv1d(self.nchan, self.n_hidden,kernel_size=10, padding=1),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential( \n",
    "            nn.Conv1d(self.n_hidden, self.n_hidden,stride=1, kernel_size=30, padding=1),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.lin = nn.Sequential(  \n",
    "        nn.Linear(self.n_hidden*9, self.n_hidden)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(self.n_hidden, self.nchan*self.nchan)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batchs =inputs.shape[0]\n",
    "        CO = F.relu(self.conv1(inputs))  \n",
    "        CO = F.relu(self.conv2(CO))  \n",
    "        lin = F.relu(self.lin(CO.reshape(CO.size(0), -1)))\n",
    "\n",
    "        output = F.softmax(self.out(lin))\n",
    "        return output.reshape(inputs.shape[0],self.nchan,self.nchan),lin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e314d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:   0%|                        | 0/15000 [00:00<?, ?it/s, L=1.9175, Lchan=0.7415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:   0%|                | 7/15000 [00:01<53:04,  4.71it/s, L=1.5477, Lchan=0.7427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795.1927490234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:   5%|▋             | 750/15000 [00:21<06:21, 37.37it/s, L=1.0068, Lchan=0.7447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:   5%|▋             | 757/15000 [00:23<30:29,  7.79it/s, L=1.0157, Lchan=0.7424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009.471923828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  10%|█▎           | 1500/15000 [00:43<06:00, 37.48it/s, L=0.8586, Lchan=0.7428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  10%|█▎           | 1508/15000 [00:44<22:03, 10.19it/s, L=0.8622, Lchan=0.7422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864.1310424804688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  15%|█▉           | 2250/15000 [01:04<05:40, 37.48it/s, L=0.7481, Lchan=0.7408]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  15%|█▉           | 2257/15000 [01:06<27:11,  7.81it/s, L=0.7752, Lchan=0.7428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766.1692504882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  20%|██▌          | 3000/15000 [01:26<05:20, 37.50it/s, L=0.6747, Lchan=0.7427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  20%|██▌          | 3008/15000 [01:27<19:44, 10.12it/s, L=0.6603, Lchan=0.7413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695.0955810546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  25%|███▎         | 3750/15000 [01:47<05:02, 37.17it/s, L=0.6031, Lchan=0.7427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  25%|███▎         | 3757/15000 [01:49<24:36,  7.62it/s, L=0.6108, Lchan=0.7406]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596.5407104492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  30%|███▉         | 4500/15000 [02:09<04:41, 37.25it/s, L=0.5497, Lchan=0.7426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  30%|███▉         | 4507/15000 [02:10<17:09, 10.19it/s, L=0.5485, Lchan=0.7434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555.9305419921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  35%|████▌        | 5250/15000 [02:30<04:23, 36.94it/s, L=0.4961, Lchan=0.7422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  35%|████▌        | 5258/15000 [02:32<16:02, 10.12it/s, L=0.4938, Lchan=0.7436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505.43463134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  40%|█████▏       | 6000/15000 [02:52<04:01, 37.31it/s, L=0.4376, Lchan=0.7423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  40%|█████▏       | 6008/15000 [02:53<14:39, 10.23it/s, L=0.4505, Lchan=0.7422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444.0587463378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  45%|█████▊       | 6750/15000 [03:13<03:39, 37.56it/s, L=0.3773, Lchan=0.7429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  45%|█████▊       | 6758/15000 [03:15<13:26, 10.22it/s, L=0.4014, Lchan=0.7440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389.01904296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  50%|██████▌      | 7500/15000 [03:35<03:23, 36.86it/s, L=0.3416, Lchan=0.7419]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007\n",
      "0.0003\n",
      "torch.Size([100, 4, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  50%|██████▌      | 7508/15000 [03:36<12:24, 10.07it/s, L=0.3219, Lchan=0.7416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.2215576171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start step 0; Training for 15000 steps:  52%|██████▋      | 7738/15000 [03:43<03:29, 34.68it/s, L=0.3214, Lchan=0.7430]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e8b1aeea56ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Start step {}; Training for {} steps'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mistep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mcurtuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrsamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mcurdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;31m#print (curdata.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-daa5f0d69da8>\u001b[0m in \u001b[0;36msreturn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m                         \u001b[0mprevarrand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mcurx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mcury\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcury\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[1;31m#print (ychan[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m#print (curx[:,0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "n_steps=15000\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "nchantot=4\n",
    "trsamp={}\n",
    "input_size=100\n",
    "ntime=140\n",
    "nepoch=n_steps/20\n",
    "biasvsal=0.01\n",
    "topred=40\n",
    "trsamp[\"train\"]=sample(nchantot,biasvsal,input_size,topred)\n",
    "trsamp[\"val\"]=sample(nchantot,biasvsal,input_size,topred,12229)\n",
    "\n",
    "\n",
    "modellstm = LSTM(nchan=nchantot,npoint=topred).to('cuda')\n",
    "modellstm.train()\n",
    "modelconv = Conv(nchan=nchantot,npoint=topred).to('cuda')\n",
    "modelconv.train()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizerlstm = torch.optim.Adam(modellstm.parameters(), lr=0.007, weight_decay=0.0)\n",
    "optimizerconv = torch.optim.Adam(modelconv.parameters(), lr=0.0003, weight_decay=0.0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerlstm, factor=0.5, patience=0, cooldown=4, verbose=True)\n",
    "fullval=trsamp[\"val\"].sreturn()\n",
    "valsamp=torch.from_numpy(fullval[0]).to('cuda')\n",
    "valsamptrue=torch.from_numpy(fullval[1]).to('cuda')\n",
    "fig, axs = plt.subplots(4)\n",
    "with tqdm(total=n_steps, desc='Start step {}; Training for {} steps'.format(0, n_steps)) as pbar:\n",
    "        for istep in range(n_steps):\n",
    "                curtuple = trsamp[\"train\"].sreturn()\n",
    "                curdata = torch.from_numpy(curtuple[0]).to('cuda')\n",
    "                #print (curdata.shape)\n",
    "\n",
    "                outputsconv  = modelconv(curdata)\n",
    "                predchantrue  = outputsconv[0]\n",
    "                topass  = outputsconv[1]\n",
    "                outputs  = modellstm((curdata,topass))\n",
    "                #print (outputs[0],curtuple[1])\n",
    "\n",
    "                curtrue = torch.from_numpy(curtuple[1]).to('cuda')\n",
    "\n",
    "        \n",
    "                curchantrue = torch.from_numpy(curtuple[2])\n",
    "                curchantrue=F.one_hot(curchantrue).to('cuda').float()\n",
    "\n",
    "\n",
    "                curpred = outputs\n",
    "                #print (curpred.shape )\n",
    "                #print (curtrue.shape )\n",
    "                #  curpred=curpred.reshape(curtrue.shape[0],curtrue.shape[1],) \n",
    "\n",
    "                #print (torch.std(curtrue-curpred))\n",
    "                #print (curtrue[0],curpred[0])\n",
    "                curtrue=curtrue.reshape(curpred.shape)\n",
    "                #print (curtrue.shape)               \n",
    "                #print (curpred.shape)               \n",
    "                loss = criterion(curpred,curtrue).mean()\n",
    "                \n",
    "\n",
    "                lossconv = nn.BCELoss()(predchantrue,curchantrue).mean()\n",
    "\n",
    "                pbar.set_postfix(L='{:.4f}'.format(loss),Lchan='{:.4f}'.format(lossconv))\n",
    "                pbar.update()\n",
    "                #optimizerconv.zero_grad()\n",
    "                optimizerlstm.zero_grad()\n",
    "                \n",
    "                #lossconv.backward(retain_graph=True)\n",
    "                loss.backward(retain_graph=False)\n",
    "                #optimizerconv.step()   \n",
    "                torch.nn.utils.clip_grad_norm_(modellstm.parameters(), 1.0)\n",
    "                optimizerlstm.step()\n",
    "\n",
    "                if (istep%nepoch==0):\n",
    "                        modellstm.eval()\n",
    "                        modelconv.eval()\n",
    "                        for param_group in optimizerlstm.param_groups:\n",
    "                                print(param_group[\"lr\"])\n",
    "                        for param_group in optimizerconv.param_groups:\n",
    "                                print(param_group[\"lr\"])\n",
    "\n",
    "                        outputsconv  = modelconv(valsamp)\n",
    "                        predchantrue  = outputsconv[0]\n",
    "                        topass  = outputsconv[1]\n",
    "                        outputs  = modellstm((valsamp,topass))\n",
    "                        print(outputs.shape)\n",
    "                        #outputs= outputs.reshape(valsamptrue.shape[0],valsamptrue.shape[1])\n",
    "\n",
    "                        #print (outputs)\n",
    "                        #print (valsamptrue) \n",
    "                        #print (np.array(xvals).shape)\n",
    "                        #print (np.array(yvals).shape)\n",
    "                        plot=True\n",
    "                        if plot:\n",
    "\n",
    "                                #plt.clf()\n",
    "\n",
    "                                axs[0].cla()\n",
    "                                axs[1].cla()\n",
    "                                axs[2].cla()\n",
    "                                axs[3].cla()\n",
    "                                #plt.plot(np.append(valsamp.cpu().numpy()[0,0,:],outputs.cpu().detach().numpy()[0,0,:]))\n",
    "                                #plt.plot(np.append(valsamp.cpu().numpy()[0,1,:],outputs.cpu().detach().numpy()[0,1,:]))\n",
    "                                axs[0].plot(np.append(valsamp.cpu().numpy()[0,0,:],outputs.cpu().detach().numpy()[0,0,:]))\n",
    "                                axs[1].plot(np.append(valsamp.cpu().numpy()[0,1,:],outputs.cpu().detach().numpy()[0,1,:]))\n",
    "                                axs[2].plot(np.append(valsamp.cpu().numpy()[0,2,:],outputs.cpu().detach().numpy()[0,2,:]))\n",
    "                                axs[3].plot(np.append(valsamp.cpu().numpy()[0,3,:],outputs.cpu().detach().numpy()[0,3,:]))\n",
    "                                #plt.xlabel(\"steps\")\n",
    "                                #plt.ylabel(\"position\")\n",
    "                                #plt.title(\"randdwalk\")\n",
    "                                plt.show(block=False)\n",
    "                                plt.pause(1)\n",
    "\n",
    "                        #sys.exit()\n",
    "                        validation_loss=criterion(outputs,valsamptrue).mean()*1000\n",
    "                        scheduler.step(validation_loss)\n",
    "                        print (validation_loss.tolist())\n",
    "                        modellstm.train()\n",
    "                        modelconv.train()\n",
    "        \n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048b040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd497c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa4467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
