{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f943cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.8.1\n",
      "torchvision 0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import super\n",
    "\"\"\"\n",
    "Implementation of Block Neural Autoregressive Flow\n",
    "http://arxiv.org/abs/1904.04676\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torchvision\n",
    "print (\"torch\",torch.__version__)\n",
    "print (\"torchvision\",torchvision.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import array\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import pprint\n",
    "import scipy\n",
    "from scipy import special\n",
    "from functools import partial\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.manifold import TSNE\n",
    "import csv\n",
    "from torch.utils import data\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64727ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------\n",
    "# Data\n",
    "# --------------------\n",
    "matplotlib.use('tkagg')\n",
    "class sample:\n",
    "    def __init__(self, nchan ,biasmag, batch_size, topred, seed=None):\n",
    "        self.biasmag=biasmag\n",
    "        self.batch_size=batch_size\n",
    "        self.nchan=nchan\n",
    "        self.seed=seed\n",
    "        self.topred=topred\n",
    "    def sreturn(self):\n",
    "        xvals=[]\n",
    "        yvals=[]\n",
    "        ychan=[]\n",
    "        if (self.seed==None):\n",
    "                rng = np.random\n",
    "        else:\n",
    "                rng = np.random.RandomState(self.seed)\n",
    "        #print (-1,1,(self.batch_size,self.nchan))\n",
    "        randonarr=rng.uniform(-1,1,(self.batch_size,self.nchan))*self.biasmag\n",
    "        #randonarr[:,1]=1.0*randonarr[:,0]+0.0*randonarr[:,1]\n",
    "\n",
    "\n",
    "        ntimep = 100+self.topred\n",
    "        for bb in range(self.batch_size):\n",
    "\n",
    "\n",
    "                curx=[]\n",
    "                cury=[]\n",
    "                prevarrand=np.array([])\n",
    "                perm=np.arange(4)\n",
    "                np.random.shuffle(perm)\n",
    "                #print(perm)\n",
    "                ychan.append(perm)\n",
    "                for nn in range(self.nchan):\n",
    "                        sinfac=rng.uniform(0.2,1.)*1.2\n",
    "                        sinarr=np.sin(np.arange(ntimep)*sinfac)*5\n",
    "                        cosfac=rng.uniform(0.2,1.)*1.2\n",
    "                        cosarr=np.cos(np.arange(ntimep)*cosfac)*5\n",
    "                        #print(sinfac)\n",
    "                        #print(cosfac)\n",
    "                        corrnoise=False\n",
    "                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                        if corrnoise:\n",
    "                                if prevarrand.size==0:\n",
    "                                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                                else:\n",
    "                                        arrand = rng.uniform(-1,1,ntimep)\n",
    "                                        arrand[nn*5:]=prevarrand[0:-1*nn*5]\n",
    "                                cs=np.cumsum(arrand)\n",
    "                        else:\n",
    "                                arrand = rng.uniform(-1,1,ntimep)\n",
    "                                cs=np.cumsum(arrand+randonarr[bb][nn])+sinarr+cosarr\n",
    "\n",
    "                        #print (sinarr) \n",
    "                        curx.append(cs[:-self.topred])\n",
    "                        cury.append(cs[-self.topred:])\n",
    "                        #curx.append(np.cumsum(arrand+randonarr[bb][0]))\n",
    "                        prevarrand=arrand\n",
    "                curx=np.array(curx)\n",
    "                cury=np.array(cury)\n",
    "                #print (ychan[-1])\n",
    "                #print (curx[:,0])\n",
    "\n",
    "                curx=curx[ychan[-1]]\n",
    "                #curx=np.transpose(curx,ychan[-1])\n",
    "                #print (curx[:,0])\n",
    "                #print ()\n",
    "                cury=cury[ychan[-1]]\n",
    "     \n",
    "                xvals.append((curx))\n",
    "                yvals.append((cury))\n",
    "                #print (np.array(xvals).shape)\n",
    "                #print (np.array(yvals).shape)\n",
    "                #plt.plot(curx)\n",
    "                #plt.xlabel(\"steps\")\n",
    "                #plt.ylabel(\"position\")\n",
    "                #plt.title(\"randdwalk\")\n",
    "                #plt.show()\n",
    "                #sys.exit()\n",
    "                #input(\"Press Enter to continue...\")\n",
    "        return np.array(xvals, dtype=\"float32\"),np.array(yvals, dtype=\"float32\"),np.array(ychan, dtype=\"int64\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa61123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stockdata:\n",
    "    def __init__(self,totsym=-1):\n",
    "        \n",
    "        self.tottime=None\n",
    "        self.values=None\n",
    "        self.range=None\n",
    "        self.corrs=None\n",
    "        self.symnames=[]\n",
    "        dirname=\"filtered/\"\n",
    "        alldown=os.listdir(dirname)\n",
    "        self.corrs={}\n",
    "        self.sigmadist=[]\n",
    "\n",
    "        maxsym=len(alldown)\n",
    "        print(\"Loading...\")\n",
    "        for ialld,alld in enumerate (alldown):\n",
    "            \n",
    "            if totsym>0:\n",
    "                maxsym=totsym\n",
    "                if ialld>totsym:\n",
    "                    break\n",
    "            if ialld%500==0:\n",
    "                print(ialld,\"/\",maxsym)\n",
    "            if alld.find(\"corr_\")!=-1:\n",
    "                continue\n",
    "\n",
    "            self.symnames.append(alld.replace(\".json\",\"\"))\n",
    "            curdf=pd.DataFrame(pd.read_json(dirname+alld))\n",
    "            mergeframe=0.5*(curdf.loc[:,\"Close\"]+curdf.loc[:,\"Open\"])\n",
    "            diffd=(curdf.loc[:,\"High\"]-curdf.loc[:,\"Low\"]) \n",
    "            \n",
    "            self.sigmadist.extend(((mergeframe-curdf.loc[:,\"Low\"])/diffd).values.tolist())\n",
    "            #print ( self.sigmadist[-1])\n",
    "            #print(mergeframe)\n",
    "            mergeframe.name=self.symnames[-1]\n",
    "            diffd.name=self.symnames[-1]\n",
    "\n",
    "            if (ialld == 0):\n",
    "                self.values=mergeframe\n",
    "                self.tottime=mergeframe.shape[0]\n",
    "                self.range=diffd\n",
    "            else:\n",
    "                self.values=pd.concat((self.values,mergeframe),axis=1) \n",
    "                self.range=pd.concat((self.range,diffd),axis=1) \n",
    "\n",
    "                \n",
    "            self.corrs[self.symnames[-1]]=pd.Series((pd.read_json(dirname+\"corr_\"+alld,typ=\"series\")))\n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa6c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "0 / 50\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sd1=stockdata(totsym=50)\n",
    "stda=((np.array(sd1.sigmadist)))\n",
    "stda = stda[~np.isnan(stda)]\n",
    "stdev=stda.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e1b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "0 / 5664\n",
      "500 / 5664\n",
      "1000 / 5664\n",
      "1500 / 5664\n",
      "2000 / 5664\n",
      "2500 / 5664\n",
      "3000 / 5664\n",
      "3500 / 5664\n",
      "4000 / 5664\n",
      "4500 / 5664\n",
      "5000 / 5664\n",
      "5500 / 5664\n"
     ]
    }
   ],
   "source": [
    "sd=stockdata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e086d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stockdatagen:\n",
    "    def __init__(self, data, nchan=10, batch_size=128, lookback=30, topred=5,stdev=0.0,seed=374561):\n",
    "        self.batch_size=batch_size\n",
    "        self.nchan=nchan\n",
    "        self.lookback=lookback\n",
    "        self.topred=topred\n",
    "        self.data=data\n",
    "        self.seed=seed\n",
    "        self.tottime=data.tottime\n",
    "        self.values=data.values\n",
    "        self.range=data.range\n",
    "        self.corrs=data.corrs\n",
    "        self.symnames=data.symnames\n",
    "        if (self.seed==None):\n",
    "                self.rng = np.random\n",
    "        else:\n",
    "                self.rng = np.random.RandomState(self.seed)\n",
    "\n",
    "    def sreturn(self,start=None,Syms=None):\n",
    "        xvalbatch=[]\n",
    "        yvalbatch=[]\n",
    "        ychanbatch=[]\n",
    "\n",
    "        maxinc=self.tottime-2*(self.lookback+self.topred)\n",
    "        \n",
    "        if Syms==None:\n",
    "            numpoints=self.batch_size\n",
    "        else:\n",
    "            numpoints=len(Syms)\n",
    "        for bb in range(numpoints):\n",
    "            if Syms==None:\n",
    "                cursym=self.rng.choice(np.array(self.symnames))\n",
    "            else:\n",
    "                cursym=Syms[bb]\n",
    "            if start==None:\n",
    "                starttime=int(random.randint(0, maxinc))\n",
    "            else:\n",
    "                starttime=int(start)\n",
    "            curcorr=self.corrs[cursym].loc[::-1]\n",
    "            xvalrange=np.abs(self.range.loc[:,cursym].iloc[starttime:starttime+self.lookback])\n",
    "            xvalsigma=self.rng.normal(loc=0.0, scale=xvalrange*stdev)\n",
    "\n",
    "            xval=[(self.values.loc[:,cursym].iloc[starttime:starttime+self.lookback]).values+xvalsigma]\n",
    "            \n",
    "            yval=[(self.values.loc[:,cursym].iloc[starttime+self.lookback:starttime+self.lookback+self.topred]).values]  \n",
    "            ychan=[1.0]\n",
    "            for ic,cc in enumerate( curcorr.index):\n",
    "                if (ic>=(self.nchan-1)):\n",
    "                    break\n",
    "                xval.append ((self.values.loc[:,cc].iloc[starttime:starttime+self.lookback]).values)\n",
    "                yval.append ((self.values.loc[:,cc].iloc[starttime+self.lookback:starttime+self.lookback+self.topred]).values)\n",
    "                ychan.append(curcorr[cc])\n",
    "            xval=np.array(xval)\n",
    "            yval=np.array(yval)\n",
    "            norm=xval[:,-1]\n",
    "            norm=norm.reshape(norm.shape[0],1)\n",
    "            xval= ((xval)/norm)-1.0\n",
    "            yval= ((yval)/norm)-1.0\n",
    "\n",
    "            xvalbatch.append(np.array(xval))\n",
    "            yvalbatch.append(np.array(yval))\n",
    "            ychanbatch.append(np.array(ychan))\n",
    "            \n",
    "            #gain=ychanbatch.max(axis=1)-xvalbatch[:,-1]\n",
    "        return(np.array (xvalbatch, dtype=\"float32\"),np.array (yvalbatch, dtype=\"float32\"),np.array (ychanbatch, dtype=\"float32\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7109d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f242358fed0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msdg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstockdatagen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnchan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m374361\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sd' is not defined"
     ]
    }
   ],
   "source": [
    "sdg=stockdatagen(sd,nchan=1, batch_size=128, lookback=30, topred=10,stdev=stdev, seed=374361)\n",
    "sdg.sreturn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15943a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afaec837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,nchan=4,ntime=100,n_hidden=256,n_layers=64,npoint=5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_layers=n_layers\n",
    "        self.ntime=ntime+npoint\n",
    "        self.nchan=nchan\n",
    "        self.npoint=npoint \n",
    "        self.output_size=self.nchan*self.npoint\n",
    "        self.ks=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.lin = nn.Sequential(  \n",
    "        nn.Linear(464, 2*400)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(self.n_hidden*self.npoint, self.output_size)\n",
    "        \n",
    "        self.out10 = nn.Linear(self.n_hidden,self.n_hidden)\n",
    "        self.out11 = nn.Linear(self.n_hidden,self.nchan*self.npoint)\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=nchan,hidden_size= self.n_hidden, num_layers=n_layers,batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size=1,hidden_size= self.n_hidden, num_layers=n_layers,batch_first=True)\n",
    "        self.lstminter = nn.LSTM(input_size=self.n_hidden,hidden_size= self.n_hidden, num_layers=n_layers,batch_first=True)\n",
    "\n",
    "        #self.soft = nn.Sequential( nn.Softmax(dim=1))\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputlstm=inputs[0]\n",
    "        inputlstmshape=inputlstm.shape\n",
    "        batchs =inputlstmshape[0]\n",
    "        inputconv=inputs[1].unsqueeze(1).transpose(1, 2)\n",
    "\n",
    "\n",
    "        h0c = torch.rand( self.n_layers, batchs, self.n_hidden).to('cuda')  \n",
    "        c0c = torch.rand( self.n_layers, batchs, self.n_hidden).to('cuda')\n",
    "        LSc,hiddenc=self.lstm1(inputconv, (h0c,c0c)) \n",
    "        print(inputconv.shape)\n",
    "        print(h0c.shape)\n",
    "        print(c0c.shape)\n",
    "\n",
    "        inputlstm=inputlstm.transpose(1, 2)\n",
    "\n",
    "        #print(LSc.shape)\n",
    "        #print(inputlstm.shape)\n",
    "        h0 = torch.rand ( self.n_layers, batchs, self.n_hidden).to('cuda')  \n",
    "        c0 = torch.rand( self.n_layers, batchs, self.n_hidden).to('cuda')\n",
    "        LS,hidden=self.lstm(inputlstm, hiddenc) \n",
    "        LS=F.relu(LS)\n",
    "        LS,hidden=self.lstminter(LS, hidden) \n",
    "        #output = self.out(torch.cat((LS[:,-1,:],LSc[:,-1,:]),dim=1))\n",
    "        LS=LS[:,-1,:].reshape(LS.size(0), -1)\n",
    "        \n",
    "        \n",
    "        #output = self.out(LS)\n",
    "        #return output.reshape(output.shape[0],self.nchan,self.npoint)\n",
    "        LS = F.relu(self.out10(LS))\n",
    "        LS = F.relu(self.out10(LS))\n",
    "        output = self.out11(LS)\n",
    "        return output.reshape(output.shape[0],self.nchan,self.npoint)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad810610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self,nchan=4,ntime=100,n_hidden=64,n_layers=10,npoint=5):\n",
    "        super(Conv, self).__init__()\n",
    "        self.n_hidden=n_hidden\n",
    "        self.n_layers=n_layers\n",
    "        self.ntime=ntime+npoint\n",
    "        self.nchan=nchan\n",
    "        self.npoint=npoint \n",
    "        self.output_size=self.nchan*self.npoint\n",
    "        self.ks=10\n",
    "\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv1d(self.nchan, self.n_hidden,kernel_size=5, padding=1),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential( \n",
    "            nn.Conv1d(self.n_hidden, self.n_hidden,stride=1, kernel_size=5, padding=1),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.lin = nn.Sequential(  \n",
    "        nn.Linear(self.n_hidden*30, self.n_hidden*2)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(2*self.n_hidden, self.nchan)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batchs =inputs.shape[0]\n",
    "        CO = F.relu(self.conv1(inputs))  \n",
    "        CO = F.relu(self.conv2(CO))  \n",
    "        flat=CO.reshape(CO.size(0), -1)\n",
    "        #6,14,30 print(flat.shape)\n",
    "\n",
    "        lin = F.relu(self.lin(flat))\n",
    "\n",
    "        output = self.out(lin)\n",
    "        return output.reshape(inputs.shape[0],self.nchan),lin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fd958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e314d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stockdatagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f75933d69080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtopred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrsamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstockdatagen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnchan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnchan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlookback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m375363\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtrsamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrsamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stockdatagen' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "trsamp={}\n",
    "nchan=20\n",
    "batch_size=16\n",
    "lookback=64\n",
    "topred=5\n",
    "\n",
    "trsamp[\"train\"]=stockdatagen(sd,nchan=nchan, batch_size=batch_size, lookback=lookback, topred=topred,stdev=stdev, seed=375363)\n",
    "trsamp[\"val\"]=trsamp[\"train\"]\n",
    "\n",
    "plt.close('all')\n",
    "n_steps=5000\n",
    "nchantot=nchan\n",
    "ntime=lookback+topred\n",
    "nepoch=int(n_steps/5)\n",
    "biasvsal=0.1\n",
    "topred=topred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "modellstm = LSTM(nchan=nchantot,npoint=topred,ntime=ntime,n_hidden=64,n_layers=2).to('cuda')\n",
    "modellstm.train()\n",
    "modelconv = Conv(nchan=nchantot,npoint=topred,ntime=ntime).to('cuda')\n",
    "modelconv.train()\n",
    "\n",
    "        \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizerlstm = torch.optim.Adam(modellstm.parameters(), lr=0.005, weight_decay=0.0)\n",
    "optimizerconv = torch.optim.Adam(modelconv.parameters(), lr=0.0001, weight_decay=0.0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizerlstm, factor=0.5, patience=0, cooldown=6, verbose=True)\n",
    "\n",
    "#valsamp=torch.from_numpy(fullval[0]).to('cuda')\n",
    "#valsamptrue=torch.from_numpy(fullval[1]).to('cuda')\n",
    "fig, axs = plt.subplots(4)\n",
    "fig1, axs1 = plt.subplots(2)\n",
    "plotuple={\"loss\":[]}\n",
    "with tqdm(total=n_steps, desc='Start step {}; Training for {} steps'.format(0, n_steps)) as pbar:\n",
    "        for istep in range(n_steps):\n",
    "            \n",
    "                optimizerlstm.zero_grad()\n",
    "                optimizerconv.zero_grad()\n",
    "                curtuple = trsamp[\"train\"].sreturn()\n",
    "                curdata = torch.from_numpy(curtuple[0]).to('cuda')\n",
    "                #print (curdata.shape)\n",
    "\n",
    "                outputsconv  = modelconv(curdata)\n",
    "                predchantrue  = outputsconv[0]\n",
    "                topass  = outputsconv[1]\n",
    "                \n",
    "                outputs  = modellstm((curdata,topass))\n",
    "                curtrue = torch.from_numpy(curtuple[1]).to('cuda')\n",
    "                #print(curtrue.shape)\n",
    "\n",
    "                #maxcurtrue = torch.sum(curtrue, 2)[:,0]/topred\n",
    "                #print(maxcurtrue.shape)        \n",
    "                #print(curtrue[:,0,0].shape)    \n",
    "                #togain=((maxcurtrue-curtrue[:,0,0])/curtrue[:,0,0])\n",
    "                #print(\"maxcurtrue\")\n",
    "                #print(maxcurtrue.shape)\n",
    "\n",
    "                #print(curdata)\n",
    "\n",
    "                curchantrue = torch.from_numpy(curtuple[2]).to('cuda').float()\n",
    "                curpred = outputs\n",
    "\n",
    "                #loss = criterion(curpred,curtrue).mean()\n",
    "\n",
    "                #print((curpred-togain)/outputs[:,-1])\n",
    "\n",
    "                \n",
    "                #print(togain)\n",
    "\n",
    "\n",
    "                lossconv = criterion(predchantrue,curchantrue).mean()\n",
    "\n",
    "\n",
    "\n",
    "                curpred.reshape(curtrue.shape)\n",
    "                #print(\"curpred\")\n",
    "                #print (curpred[0,0,:])\n",
    "                #print(\"curtrue\")\n",
    "                #print (curtrue[0,0,:])\n",
    "                loss = 100.*criterion(curpred,curtrue)+lossconv\n",
    "                loss.backward(retain_graph=True)\n",
    "                #torch.nn.utils.clip_grad_norm_(modellstm.parameters(), 0.1)\n",
    "                optimizerlstm.step()\n",
    "                \n",
    "\n",
    "                #lossconv.backward(retain_graph=False)\n",
    "                #torch.nn.utils.clip_grad_norm_(modelconv.parameters(), 0.05)\n",
    "                \n",
    "                optimizerconv.step()   \n",
    "                \n",
    "                pbar.set_postfix(L='{:.4f}'.format(loss),Lchan='{:.4f}'.format(lossconv))\n",
    "                pbar.update()\n",
    "                if (istep%nepoch==0 and istep>0):\n",
    "                        modellstm.eval()\n",
    "                        modelconv.eval()\n",
    "                        lateststart= sd.tottime - ntime \n",
    "                        fullval=trsamp[\"val\"].sreturn(start=lateststart,Syms=sd.symnames)\n",
    "                        \n",
    "                        plotuple[\"loss\"].append(loss.detach().cpu().numpy())\n",
    "                        valsamp=torch.from_numpy(fullval[0]).to('cuda')\n",
    "                        valsamptrue=torch.from_numpy(fullval[1]).to('cuda')\n",
    "\n",
    "                        for param_group in optimizerlstm.param_groups:\n",
    "                                print(param_group[\"lr\"])\n",
    "                        for param_group in optimizerconv.param_groups:\n",
    "                                print(param_group[\"lr\"])\n",
    "\n",
    "                        \n",
    "                        outputsconv  = modelconv(valsamp)\n",
    "                        predchantrue  = outputsconv[0]\n",
    "                        topass  = outputsconv[1]\n",
    "                        outputs  = modellstm((valsamp,topass))\n",
    "\n",
    "                        \n",
    "                        curtrue = torch.from_numpy(fullval[1]).to('cuda')\n",
    "                        #maxcurtrue = torch.mean(curtrue, 2)[:,0]\n",
    "                        #togain=((maxcurtrue-curtrue[:,:,0])/curtrue[:,:,0])[:,0]  \n",
    "                        curpred = outputs\n",
    "                        #argm=(np.argsort(togain.detach().cpu().numpy()))\n",
    "\n",
    "                        #outputs= outputs.reshape(valsamptrue.shape[0],valsamptrue.shape[1])\n",
    "\n",
    "                        #print (outputs)\n",
    "                        #print (valsamptrue) \n",
    "                        #print (np.array(xvals).shape)\n",
    "                        #print (np.array(yvals).shape)\n",
    "                        plot=True\n",
    "                        if plot:\n",
    "\n",
    "                                #plt.clf()\n",
    "        \n",
    "                                axs[0].cla()\n",
    "                                axs[1].cla()\n",
    "                                axs[2].cla()\n",
    "                                axs[3].cla()\n",
    "                                #plt.plot(np.append(valsamp.cpu().numpy()[0,0,:],outputs.cpu().detach().numpy()[0,0,:]))\n",
    "                                #plt.plot(np.append(valsamp.cpu().numpy()[0,1,:],outputs.cpu().detach().numpy()[0,1,:]))\n",
    "                                bnum=11\n",
    "                                axs[0].plot(np.append(valsamp.cpu().numpy()[bnum,0,:],outputs.cpu().detach().numpy()[bnum,0,:]))\n",
    "                                axs[1].plot(np.append(valsamp.cpu().numpy()[bnum,1,:],outputs.cpu().detach().numpy()[bnum,1,:]))\n",
    "                                axs[2].plot(np.append(valsamp.cpu().numpy()[bnum,2,:],outputs.cpu().detach().numpy()[bnum,2,:]))\n",
    "                                axs[3].plot(np.append(valsamp.cpu().numpy()[bnum,3,:],outputs.cpu().detach().numpy()[bnum,3,:]))\n",
    "                                axs[0].plot(np.append(valsamp.cpu().numpy()[bnum,0,:],curtrue.cpu().detach().numpy()[bnum,0,:]))\n",
    "                                axs[1].plot(np.append(valsamp.cpu().numpy()[bnum,1,:],curtrue.cpu().detach().numpy()[bnum,1,:]))\n",
    "                                axs[2].plot(np.append(valsamp.cpu().numpy()[bnum,2,:],curtrue.cpu().detach().numpy()[bnum,2,:]))\n",
    "                                axs[3].plot(np.append(valsamp.cpu().numpy()[bnum,3,:],curtrue.cpu().detach().numpy()[bnum,3,:]))\n",
    "                                #for ipl in range(10):\n",
    "                                    #axs[0].plot(np.append(valsamp.cpu().numpy()[argm[-ipl],0,:],valsamptrue.cpu().detach().numpy()[argm[-ipl],0,:]))\n",
    "                                    #axs[1].plot(np.append(valsamp.cpu().numpy()[argm[ipl],0,:],valsamptrue.cpu().detach().numpy()[argm[ipl],0,:]))\n",
    "                                #    axs[0].plot((valsamp.cpu().numpy()[argm[-ipl],0,:]))\n",
    "                                 #   axs[1].plot((valsamp.cpu().numpy()[argm[ipl],0,:]))\n",
    "                                  #  axs[2].plot((valsamptrue.cpu().detach().numpy()[argm[-ipl],0,:]/valsamptrue.cpu().detach().numpy()[argm[-ipl],0,:].mean()))\n",
    "                                   # axs[3].plot((valsamptrue.cpu().detach().numpy()[argm[ipl],0,:]/valsamptrue.cpu().detach().numpy()[argm[ipl],0,:].mean()))\n",
    "                                axs1[0].cla()\n",
    "                                axs1[0].plot(plotuple[\"loss\"])\n",
    "\n",
    "                                #plt.xlabel(\"steps\")\n",
    "                                #plt.ylabel(\"position\")\n",
    "                                #plt.title(\"randdwalk\")\n",
    "                                plt.show(block=False)\n",
    "                                plt.pause(1)\n",
    "                        modellstm.train()\n",
    "                        modelconv.train()\n",
    "                        #sys.exit()\n",
    "                        #validation_loss=criterion(outputs,valsamptrue).mean()*1000\n",
    "                        #scheduler.step(validation_loss)\n",
    "                        #print (validation_loss.tolist())\n",
    "\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048b040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd497c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
